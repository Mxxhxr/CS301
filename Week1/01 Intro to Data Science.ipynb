{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INLD2p-49kie"
   },
   "source": [
    "# What is Data Science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU0v2iOEA0ku"
   },
   "source": [
    "\n",
    "Data science is a multidisciplinary field that combines expertise from various domains, including **statistics, mathematics, and computer science**, to analyze and interpret complex data. The goal of data science is to uncover **patterns and valuable information** that can help in decision-making and solve data driven problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTRfwHXZDewR"
   },
   "source": [
    "# Key Steps of a Data Science Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME4ypkLLDdB9"
   },
   "source": [
    "1. **Data Collection:** Gathering relevant data from various sources, which may include databases, files, APIs, sensors, and more.\n",
    "\n",
    "2. **Data Cleaning and Preprocessing:** Ensuring data quality by handling missing values, outliers, and other inconsistencies.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA):** Examining and visualizing the data to understand its characteristics, identify patterns, and generate hypotheses.\n",
    "\n",
    "4. **Statistical Analysis:** Applying statistical methods to draw inferences from the data, test hypotheses, and quantify uncertainty.\n",
    "\n",
    "5. **Machine Learning:** Building predictive models and making sense of complex relationships within the data. Machine learning algorithms are used for tasks like regression, classification, clustering, and recommendation.\n",
    "\n",
    "6. **Feature Engineering:** Transforming or creating features (variables) to improve the performance of machine learning models.\n",
    "\n",
    "7. **Model Evaluation and Validation:** Assessing the performance of models using appropriate metrics and ensuring that they generalize well to new, unseen data.\n",
    "\n",
    "8. **Deployment:** Integrating models and insights into business processes, applications, or decision-making systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cge2YGYM9pMA"
   },
   "source": [
    "# Tools and Technologies Used in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlgvaQ3gnIxY"
   },
   "source": [
    "Data science involves a variety of tools and technologies to collect, process, analyze, and visualize data. The choice of tools depends on the specific tasks, the nature of the data, and the preferences of the data scientists. Here are some commonly used tools in data science:\n",
    "\n",
    "1. **Programming Languages:**\n",
    "   - **Python:** Widely used for its versatility, extensive libraries (e.g., NumPy, pandas, scikit-learn), and strong support in the data science community.\n",
    "   - **R:** Particularly popular for statistical analysis and data visualization.\n",
    "\n",
    "2. **Integrated Development Environments (IDEs):**\n",
    "   - **Jupyter Notebooks:** Interactive and widely used for data exploration, visualization, and analysis. Supports multiple programming languages, including Python and R.\n",
    "   - **RStudio:** An IDE specifically designed for R, providing a user-friendly environment for data analysis and visualization.\n",
    "\n",
    "3. **Big Data Tools:**\n",
    "   - **Apache Spark:** A fast, in-memory data processing engine for big data processing and analysis.\n",
    "   - **Hadoop:** A distributed storage and processing framework commonly used for big data analytics.\n",
    "\n",
    "4. **Database Systems:**\n",
    "   - **SQL:** For querying and managing relational databases.\n",
    "   - **MongoDB:** A NoSQL database often used for handling unstructured data.\n",
    "\n",
    "\n",
    "5. **Cloud Platforms:**\n",
    "   - **AWS, Azure, Google Cloud:** Cloud platforms provide scalable infrastructure and services for data storage, processing, and analysis.\n",
    "\n",
    "6. **Collaboration and Documentation:**\n",
    "    - **GitHub, GitLab:** Platforms for hosting and collaborating on code repositories.\n",
    "    - **Confluence, Jira:** Tools for documentation and project management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WrEdRZV2icR"
   },
   "source": [
    "# Introduction to Google Colab\n",
    "Google Colab, short for Google Colaboratory, is a free, cloud-based platform provided by Google that allows users to write and execute Python code collaboratively. It provides access to Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs) that helps for tasks that involve heavy computation, such as machine learning and deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BFCUqu82mQF"
   },
   "source": [
    "Using Google Colab (Colaboratory) is quite straightforward. Here are the basic steps to use Google Colab:\n",
    "\n",
    "1. **Access Google Colab:**\n",
    "   Open your web browser and go to [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "2. **Sign In with Google:**\n",
    "   If you are not already signed in to your Google account, you will be prompted to sign in. If you don't have a Google account, you'll need to create one.\n",
    "\n",
    "3. **Create a New Notebook:**\n",
    "   Once you're signed in, you can create a new notebook by clicking on the \"New notebook\" button.\n",
    "\n",
    "4. **Writing and Executing Code:**\n",
    "   Google Colab notebooks work similarly to Jupyter notebooks. You can write and execute code in cells. To run a cell, either click the **\"Play\"** button next to the cell or press **Shift + Enter**. Colab supports both code and text cells.\n",
    "\n",
    "5. **Saving and Sharing Notebooks:**\n",
    "   You can save your Colab notebook to Google Drive by clicking on \"File\" -> \"Save a copy in Drive.\" This allows you to keep your work and share it with others.\n",
    "\n",
    "6. **Adding Code and Text Cells:**\n",
    "   You can add new cells by clicking on the \"+\" button above the notebook. You can choose whether the cell should be a code cell or a text cell.\n",
    "\n",
    "\n",
    "7. **GPU Support:**\n",
    "   Colab provides free access to GPU resources. You can enable GPU support by clicking on \"Runtime\" -> \"Change runtime type\" and selecting \"GPU\" under the \"Hardware accelerator\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1gavUMBXcHT"
   },
   "source": [
    "# Introduction to Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg-lGodb8k7_"
   },
   "source": [
    "NumPy is a powerful library in Python that is widely used in the field of data science, machine learning, and scientific computing. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "\n",
    "Key features of NumPy include:\n",
    "\n",
    "1. **Arrays:** At the core of the NumPy package, is the **ndarray** object that encapsulates n-dimensional arrays of homogeneous data types. These arrays are more **efficient** than Python lists for numerical operations.\n",
    "\n",
    "2. **Indexing and Slicing:** NumPy provides powerful indexing and slicing capabilities for accessing and manipulating data within arrays. This makes it easy to extract subsets of data or modify specific elements.\n",
    "\n",
    "3. **Broadcasting:** NumPy allows for operations between arrays of different shapes and sizes through a mechanism called broadcasting. This makes it easy to perform element-wise operations on arrays of different shapes without the need for explicit looping or reshaping.\n",
    "\n",
    "4. **Parallelization:** NumPy operations can be parallelized, as they are often implemented using optimized low-level libraries that take advantage of parallel processing capabilities on modern hardware.\n",
    "\n",
    "NumPy is a foundational library in the Python data science ecosystem and is often used in conjunction with other libraries like Pandas, Matplotlib, and scikit-learn for tasks such as data manipulation, analysis, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvMLPVa3V_YA"
   },
   "source": [
    "### ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIRS-b63V_YA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "arr_3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg0vxMqzI7qn"
   },
   "source": [
    "Some key points about ndarray and its attributes:\n",
    "\n",
    "1. **Axis:**\n",
    "  - In NumPy, arrays can have one or more dimensions, and each dimension is referred to as an \"axis.\"\n",
    "\n",
    "  - Many NumPy functions allow operations to be performed along a specified axis. Common operations include ```sum, mean, minimum, maximum,``` etc. The axis parameter in these operations specify the direction along which an operation is applied. For example, when summing a 3D array along axis 0, the operation is performed along columns; when summing along axis 1, the operation is performed along rows.\n",
    "\n",
    "2. **Shape:**\n",
    "   - The \"shape\" of an ndarray refers to a tuple representing the dimensions of the array. For example, a 1-dimensional array might have a shape like ```(5,)```, indicating it has 5 elements along a single axis. A 2-dimensional array might have a shape like ```(3, 4)```, indicating it has 3 rows and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Aaeymv30Kf-y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of arr_1d: (3,)\n",
      "shape of arr_2d: (2, 3)\n",
      "shape of arr_3d: (2, 2, 3)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "arr_3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "print(\"shape of arr_1d:\",arr_1d.shape)\n",
    "print(\"shape of arr_2d:\",arr_2d.shape)\n",
    "print(\"shape of arr_3d:\",arr_3d.shape)\n",
    "print(arr_3d.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "\n",
      "\n",
      "[ 6 15]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(arr_2d)\n",
    "print(\"\\n\\n\")\n",
    "# Sum along axis 0 (columns) & 1 (rows)\n",
    "column_sum = np.sum(arr_2d, axis=1)\n",
    "print(column_sum)  # Output: [5 7 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfSvHc4sV_YC"
   },
   "source": [
    "### Data Types of ndarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNiM3d6qalvk"
   },
   "source": [
    "Understanding data types in NumPy is crucial as it allows us to control how data is stored in memory and how operations are performed on that data. NumPy provides a rich set of data types that are more efficient than the built-in Python types.\n",
    "\n",
    "Here are some key data types in NumPy:\n",
    "\n",
    "1. **int8, int16, int32, int64**: Signed integers with 8, 16, 32, or 64 bits of precision, respectively.\n",
    "\n",
    "2. **uint8, uint16, uint32, uint64**: Unsigned integers with 8, 16, 32, or 64 bits of precision, respectively.\n",
    "\n",
    "3. **float16, float32, float64**: Floating-point numbers with 16, 32, or 64 bits of precision, respectively.\n",
    "\n",
    "4. **complex64, complex128**: Complex numbers with 64 or 128 bits of precision, where the real and imaginary parts are represented by 32 or 64-bit floating-point numbers.\n",
    "\n",
    "5. **bool**: Boolean type storing True or False values.\n",
    "\n",
    "6. **object**: A generic object data type. It is often used when dealing with heterogeneous data or when the elements of the array need to be arbitrary Python objects.\n",
    "\n",
    "7. **string_**: String data type.\n",
    "\n",
    "8. **unicode_**: Unicode data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zXG_VyI7D91"
   },
   "source": [
    "**You can specify the data type when creating a NumPy array using the `dtype` parameter.** For example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "# define the data type during array creation\n",
    "arr1 = np.array([1, 2, 3], dtype=np.int32)\n",
    "arr2 = np.array([1, 2, 3], dtype='int32')\n",
    "```\n",
    "You can change the data type of an array after it has been created using the `astype` function.\n",
    "```python\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "float_arr = arr.astype(np.float32)\n",
    "print(arr.dtype,float_arr.dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "float_arr = arr.astype(np.float32)\n",
    "print(arr.dtype,float_arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "INLD2p-49kie",
    "bTRfwHXZDewR",
    "cge2YGYM9pMA",
    "0WrEdRZV2icR",
    "r1gavUMBXcHT",
    "vvMLPVa3V_YA",
    "kfSvHc4sV_YC"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
